{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "import spacy\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common_my_NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_frequency_dict(dictionary, neg_sentences, non_sentences):\n",
    "    # idx = 0\n",
    "\n",
    "    for sentence in neg_sentences:\n",
    "        for word in sentence:\n",
    "            \n",
    "            if word not in dictionary:\n",
    "                dictionary[word] = 0\n",
    "                # idx += 1\n",
    "            \n",
    "            dictionary[word] += 1\n",
    "    \n",
    "    for sentence in non_sentences:\n",
    "        for word in sentence:\n",
    "            \n",
    "            if word not in dictionary:\n",
    "                dictionary[word] = 0\n",
    "                # idx += 1\n",
    "            \n",
    "            dictionary[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_idx_dict(dictionary, neg_sentences, non_sentences):\n",
    "    idx = 0\n",
    "\n",
    "    for sentence in neg_sentences:\n",
    "        for word in sentence:\n",
    "            \n",
    "            if word not in dictionary:\n",
    "                dictionary[word] = idx\n",
    "                idx += 1\n",
    "            \n",
    "            # dictionary[word] += 1\n",
    "    \n",
    "    for sentence in non_sentences:\n",
    "        for word in sentence:\n",
    "            \n",
    "            if word not in dictionary:\n",
    "                dictionary[word] = idx\n",
    "                idx += 1\n",
    "            \n",
    "            # dictionary[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmv_frequency_dict(dictionary, low_bound):\n",
    "    rmv_list = []\n",
    "    for key, value in dictionary.items():\n",
    "        if value <= low_bound:\n",
    "            rmv_list.append(key)\n",
    "    \n",
    "    for word in rmv_list:\n",
    "        dictionary.pop(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_dictionary(dictionary):\n",
    "    idx = 0\n",
    "\n",
    "    for key, value in dictionary.items():\n",
    "        dictionary[key] = idx\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    train_neg = pd.read_csv('data/train.negative.csv', quotechar=None, quoting=3, sep='\\t', header=None)\n",
    "    train_non = pd.read_csv('data/train.non-negative.csv', quotechar=None, quoting=3, sep='\\t', header=None)\n",
    "\n",
    "    test_neg = pd.read_csv('data/test.negative.csv', quotechar=None, quoting=3, sep='\\t', header=None)\n",
    "    test_non = pd.read_csv('data/test.non-negative.csv', quotechar=None, quoting=3, sep='\\t', header=None)\n",
    "\n",
    "    # train_neg.head()\n",
    "\n",
    "\n",
    "    # train_neg[0] = train_neg[0].apply(lambda x: my_NLP.remove_html(x))\n",
    "    # train_non[0] = train_non[0].apply(lambda x: my_NLP.remove_html(x))\n",
    "\n",
    "    # test_neg[0] = test_neg[0].apply(lambda x: my_NLP.remove_html(x))\n",
    "    # test_non[0] = test_non[0].apply(lambda x: my_NLP.remove_html(x))\n",
    "\n",
    "\n",
    "    train_neg[0] = train_neg[0].apply(lambda x: common_my_NLP.remove_punctuation(x))\n",
    "    train_non[0] = train_non[0].apply(lambda x: common_my_NLP.remove_punctuation(x))\n",
    "\n",
    "    test_neg[0] = test_neg[0].apply(lambda x: common_my_NLP.remove_punctuation(x))\n",
    "    test_non[0] = test_non[0].apply(lambda x: common_my_NLP.remove_punctuation(x))\n",
    "\n",
    "\n",
    "    train_neg[0] = train_neg[0].apply(lambda x: x.lower())\n",
    "    train_non[0] = train_non[0].apply(lambda x: x.lower())\n",
    "\n",
    "    test_neg[0] = test_neg[0].apply(lambda x: x.lower())\n",
    "    test_non[0] = test_non[0].apply(lambda x: x.lower())\n",
    "\n",
    "\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    tok_lem_sentence_train_neg = [[token.lemma_ for token in nlp(row[0].strip())] for index, row in train_neg.iterrows()]\n",
    "    tok_lem_sentence_train_non = [[token.lemma_ for token in nlp(row[0].strip())] for index, row in train_non.iterrows()]\n",
    "\n",
    "    tok_lem_sentence_test_neg = [[token.lemma_ for token in nlp(row[0].strip())] for index, row in test_neg.iterrows()]\n",
    "    tok_lem_sentence_test_non = [[token.lemma_ for token in nlp(row[0].strip())] for index, row in test_non.iterrows()]\n",
    "\n",
    "    # tok_lem_sentence_train_neg[0]\n",
    "\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    rmv_sw_sentence_train_neg = [ [word for word in sentence if not word in stop_words and word != ' '] for sentence in tok_lem_sentence_train_neg]\n",
    "    rmv_sw_sentence_train_non = [ [word for word in sentence if not word in stop_words and word != ' '] for sentence in tok_lem_sentence_train_non]\n",
    "\n",
    "    rmv_sw_sentence_test_neg = [ [word for word in sentence if not word in stop_words and word != ' '] for sentence in tok_lem_sentence_test_neg]\n",
    "    rmv_sw_sentence_test_non = [ [word for word in sentence if not word in stop_words and word != ' '] for sentence in tok_lem_sentence_test_non]\n",
    "\n",
    "    # rmv_sw_sentence_test_neg[0]\n",
    "\n",
    "    dictionary = {}\n",
    "    make_frequency_dict(dictionary, rmv_sw_sentence_train_neg, rmv_sw_sentence_train_non)\n",
    "    # make_idx_dict(dictionary, rmv_sw_sentence_train_neg, rmv_sw_sentence_train_non)\n",
    "\n",
    "    # dictionary\n",
    "\n",
    "\n",
    "    rmv_frequency_dict(dictionary, 3)\n",
    "\n",
    "    # dictionary\n",
    "\n",
    "\n",
    "    idx_dictionary(dictionary)\n",
    "\n",
    "    # dictionary\n",
    "\n",
    "\n",
    "    train_neg_len = len(rmv_sw_sentence_train_neg)\n",
    "    train_non_len = (len(rmv_sw_sentence_train_non)*2)-124\n",
    "\n",
    "    test_neg_len = len(rmv_sw_sentence_test_neg)\n",
    "    test_non_len = len(rmv_sw_sentence_test_non)\n",
    "\n",
    "    train_row_len = (train_neg_len + train_non_len)\n",
    "    test_row_len = (test_neg_len + test_non_len)\n",
    "    col_len = len(dictionary)\n",
    "\n",
    "    train_x = np.zeros((train_row_len, col_len))\n",
    "    test_x = np.zeros((test_row_len, col_len))\n",
    "\n",
    "    # train_x.shape\n",
    "\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    for sentence in rmv_sw_sentence_train_neg:\n",
    "        for word in sentence:\n",
    "            if word in dictionary:\n",
    "                place = dictionary[word]\n",
    "                train_x[idx][place] = 1\n",
    "        idx += 1\n",
    "\n",
    "    for sentence in rmv_sw_sentence_train_non:\n",
    "        for word in sentence:\n",
    "            if word in dictionary:\n",
    "                place = dictionary[word]\n",
    "                train_x[idx][place] = 1\n",
    "        idx += 1\n",
    "\n",
    "    for sentence in rmv_sw_sentence_train_non[:-124]:\n",
    "        for word in sentence:\n",
    "            if word in dictionary:\n",
    "                place = dictionary[word]\n",
    "                train_x[idx][place] = 1\n",
    "        idx += 1\n",
    "\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    for sentence in rmv_sw_sentence_test_neg:\n",
    "        for word in sentence:\n",
    "            if word in dictionary:\n",
    "                place = dictionary[word]\n",
    "                test_x[idx][place] = 1\n",
    "        idx += 1\n",
    "\n",
    "    for sentence in rmv_sw_sentence_test_non:\n",
    "        for word in sentence:\n",
    "            if word in dictionary:\n",
    "                place = dictionary[word]\n",
    "                test_x[idx][place] = 1\n",
    "        idx += 1\n",
    "\n",
    "\n",
    "    train_y_non_set = np.ones((train_neg_len, 1))\n",
    "    train_y_non_unset = np.zeros((train_neg_len, 1))\n",
    "    train_y_neg_unset = np.zeros((train_non_len, 1))\n",
    "    train_y_neg_set = np.ones((train_non_len, 1))\n",
    "\n",
    "    tmp_train_y_non = np.concatenate((train_y_non_set, train_y_non_unset), axis=1)\n",
    "    tmp_train_y_neg = np.concatenate((train_y_neg_unset, train_y_neg_set), axis=1)\n",
    "\n",
    "    test_y_non_set = np.ones((test_neg_len, 1))\n",
    "    test_y_non_unset = np.zeros((test_neg_len, 1))\n",
    "    test_y_neg_unset = np.zeros((test_non_len, 1))\n",
    "    test_y_neg_set = np.ones((test_non_len, 1))\n",
    "\n",
    "    tmp_test_y_non = np.concatenate((test_y_non_set, test_y_non_unset), axis=1)\n",
    "    tmp_test_y_neg = np.concatenate((test_y_neg_unset, test_y_neg_set), axis=1)\n",
    "\n",
    "    # print(tmp_train_y_non.shape, tmp_train_y_neg.shape)\n",
    "    # print(tmp_test_y_non.shape, tmp_test_y_neg.shape)\n",
    "\n",
    "\n",
    "    train_y = np.concatenate((tmp_train_y_non, tmp_train_y_neg), axis=0)\n",
    "    test_y = np.concatenate((tmp_test_y_non, tmp_test_y_neg), axis=0)\n",
    "\n",
    "    # print(train_y.shape, test_y.shape)\n",
    "\n",
    "\n",
    "    # print(train_x.shape, train_y.shape)\n",
    "    # print(test_x.shape, test_y.shape)\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
